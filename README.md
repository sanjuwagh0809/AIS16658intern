Task 1 : 1] task 1 - Variable:studied the rule of variable declarion in python .2] task 1- operators : studied various operator in python namely Arithmatic , Assignment,logical,identity,comparison,Bitwise,membership etc .3] task 1 -list : studied the data type list and its method like append remove insert pop sort count accessing , copy reverse and its properties.4] task 1 - tuples : studied how to declear tuple its method like count index etc.5] task 1 -set : set declaration ,properties like mutable , ordered,etc.6] task 1-dictionry: declaration of dict,methods like copy index pop and use of for loop for acceessing 7] task 1 -string : declaration and use of functions like upper lower split strip replace etc.8] task 1-number: substeps like int float and complex,its method.

Task 2 : 1] task 2 - if stmt : use of if statement to check a single condition in various example like to check whether a number is positive
negative,even odd etc.2] task 2 - if else stmt : used to check two condition in example like checking a number is even or odd , greater or smaller , negative or positive and other similar examples. 3] task 2 - if elif else : to test multiple condition at a time if the above condition false then the next one to it tested. studied examples like to ckeck whether number is positive negative or zero and other similar examples.4] task 2 - for loop : used for accessing the elements in a list tuple and its method . 5] task 2 - while loop : use of while  loop to print a sequence of number print.

 Task 3 : In task 3 we studied the break , pass ,continue statement also we studies User defined functions like Satistical like mean , median, mode etc. ahd logical(odd,even,grades)#break - Functionality : when break encounterd inside  loop . the loop stop its execution and cortrol is transferred to the immedately following the loop .Use cas it is useful when you want to exist a loop as soon as certain condition is proceed with the next iteration use case it is usefulwhen you want to exist a loop as soon as  certain condition is met avoidin unnecessary interation # Continue Functionality : When continue is encountered, the current iteration is terminated and the loop proceed with the next iteration .Use case It is useful you want to skip over some parts of the loop but continue with the next iterations for instance you might want to skip over even numbers or any specifice condition within a loop #pass functionality: The pass statement does nothing and is used as a placeholder.Use case It is useful when a statement is synthetically required,but you do not want any action to be taken.Commonly used during development as a placeholder for future code, in empty function or class definations,or within conditional statements where you plan to add code later #Statistical User-Defined Functions : Statistical functions are essentials for data analysis and help summarize and undersand the data's property Mean is used to calculate average of list of numbers Median is use to find the middle value of a list numbers.Mode is used find most frequently occuring values in a list numbers. Variance used to measure spread of numbers in a list from the mean. Standard devation is used to measure the amount of variation or dispersion of set of values . Percentile is used to determine the value below which a given percentage of observationa fall range is used to calculate the difference between the maximum and minimum values in list .interquartile Range (IQR) is used to measure middle 50 % of data . Covariance is used to measure how two variable change together . Correlation Coefficient used to
 measure  the strenght and direction of the relationship between two variables #Logical User Defined Functions #even purpose: Check if a number is even # is odd_Purpose Check if number is odd # Check if number  is prime . Check palindrome purpose etc.

Task 4 : In task 4 we studied all about Numpy library Starting with a basic introduction and ends up with creating and plotting random data set and working with NumPy functions #NumPy is open sourse project that enables numerical computing with python numPy will always be 100 % open source software and free for all use . We studied 1) creating arrays 2) array indexing  3) slicing 4) NumPy datatypes 5) Copy and View 6) array shape or reshape 7) array iterting 8) join splits, sort and filter . Here 1D array,3D array and multidimensional array are studied Numpy has some extra data types, and refer to data types with one cheracter like i for integers,u for unsigned integers etc # Then we learn how to generate Random Number NumPy offers the random module to work with random numbers #Data disribution is a list of all possible values,and how often each value occurs Such lists are important when working with Statistical and data science .The random module offer methods that return randomly generated data distributions. Then we see that generation of random numbers from particular distribuction and visuallisation  of that distribution like Normal distribution ,binomial distribution ,poission distribution ,unifrom distribution ,
logistic distribution , mutinomail,exponential,chi squre etc.To plot the graph of distributons #from NumPy import random #import matplotlib pyplotas plt #import seaborn as sns.Then we use ufuncs stands for "Univeral Functions" and they are NumPy functions that operate on the ndarray object .We studied ufunctiuons like simple arithmatic,                                                      roundindecimals,log,summations,products,differences,finding,lcm,gcd,trignometric functions,hyperbolic function and set operations.

Task 5 : In task 5 we studied pandas in python .
#Series : A pandas Series is like a cloumn in a table . It is a one dimensional array holding data of any type.We also studied how to read csv and xlsx file in python.we create DataFrame using matrix and dictionary. we also studied DataFrame operations like value counts, apply unique,nunique ,describe,head,tail,and info .
We also studied DataFrame operations like value counts,apply unique ,nunique ,describe , head, tail and info.
We studied how to select perticular row, column in python, We also studied conditional selection,adding,deleting and updating a perticular column,indexing and remove indexing .How to use operations like addition ,substraction,multiplcation ,division between two columns.
we studied checking of missing values in data, studied missing values drop by columns also studied filling of missing values by using mean and median.

Task 6 : In task 6 we studied that Matplotlib and seaborn libarary.
We Matplotlib is a graph plotting libarary in python that serves as visualization utility.
pyplot 
pyplot
Most of the Matplotlib utilities lies undr the pyplot submodule,and are usually imported under the plt alias:
import matplotlib.pyplot as plt 
 plot x and y
plot() function is uesd to draw points (markers) in a diagram.
In matplotlib wa studied matplotlib plotting with markers,lines,label,grid,subplot,sctter plot,bar,box plot,Violine plot,Heatmap,pairplot,residual plot.
# Seaborn library 
It provides a hight -level interface for drawing attractive and informative statistical graphics. 
 Seaborn is built on top of Matplotlib and closely integrated with Pandas data structures, making it particularly convenient for working with DataFrame objects.
Once installed ,you can import it in your Python script or Jupyter Notebook:
import seaborn as sns
In seaborn libarary we see differnt types of plotting of graphs such as Scatter plot ,Line plot,bar box,Violin plot Heatmap.pairplot,residual plot.

Task 7 : 1] Numpy exercise:- solved problems related to array indexing slicing,creating arrays containg zeros ones generating random numbers from normal distribution,
using linspace addition of elements in an array calculate mean standard deviation, etc
2]Ecommerce purchase exercise:- studied the how to read the file and found out the mean purchase price maximum and minimum purchase price,number of people having job title lawyer number of people making the purchase during the AM and how many people made the purchase during PM,5 most common Job Titles,person with the following Credit Card Number: 4926535242672853 ,number of people have American Express as their Credit Card Provider and made a purchase above $95,number of people have a credit card that expires in 2025,top 5 most popular email providers/hosts (e.g. gmail.com, yahoo.com, etc...)
3] Salary exercise:-studied the data read the file and found out average BasePay,the highest amount of OvertimePay in the dataset,job title of JOSEPH DRISCOLL, How much does JOSEPH DRISCOLL make,name of highest paid person,name of lowest paid person,the average (mean) BasePay of all employees per year,number of unique job titles,the top 5 most common jobs,number of  Job Titles were represented by only one person in 2013, people have the word Chief in their job title,there a correlation between length of the Job Title string and Salary.

Task 8 :Case study 
In this case study we download the titanic data from kaggle and import it to jupyter notebook.Then we find the missing values and filled the missing values by its mean ,and droped the variable like cabin,passenger id etc. Then we do label encoding for the categorical variable.
Then Performd the EDA i.e exploratory data analysis on titanic data such as bar plot,scatter plot,joint plot and pie chart .
From the graph it is seen that the females are survived more than males.The passengers who are in class 1st are most survived as compared to class 2nd and 3rd.
In titanic data survival is the dependent variable and other variables like age,sex,fare,sibps,embarked are independent variables.
Then we split data into train test and fit the algorithms like naive bayes,KNN, dicision tree and predict the text data using particular fitted model.
In model evaluation we find accuracy,classification report,confusion matrix,precision and recall for each algorithm .and compare it with each other and we may conclude that 
decision tree is the best model on the basis of prcision , accuracy and recall, Where the values of precision,accuracy and recall for dicision tree are high as compared to knn and naive bayes.
Case study 
In this case study we download the titanic data from kaggle and import it to jupyter notebook.Then we find the missing values and filled the missing values by its mean ,and droped the variable like cabin,passenger id etc. Then we do label encoding for the categorical variable.
Then Performd the EDA i.e exploratory data analysis on titanic data such as bar plot,scatter plot,joint plot and pie chart .
From the graph it is seen that the females are survived more than males.The passengers who are in class 1st are most survived as compared to class 2nd and 3rd.
In titanic data survival is the dependent variable and other variables like age,sex,fare,sibps,embarked are independent variables.
Then we split data into train test and fit the algorithms like naive bayes,KNN, dicision tree and predict the text data using particular fitted model.
In model evaluation we find accuracy,classification report,confusion matrix,precision and recall for each algorithm .and compare it with each other and we may conclude that 
decision tree is the best model on the basis of prcision , accuracy and recall, Where the values of precision,accuracy and recall for dicision tree are high as compared to knn and naive bayes.

Task 9 : Dashboard
In this task we created a dashoard on project data i.e Airlines Delay Classification in power bi dashboard.We download the Airlines Delay Classification from kaggle. In power bi we get the data from csv file then by using graphs ,sclicers,card and other features we create a dashoard in power bi.



